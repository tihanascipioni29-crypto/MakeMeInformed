<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Page 6 — Make Me Informed</title>
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="https://use.typekit.net/liy1hgd.css">
</head>
<body>

<div class="page">

<!-- page6.html: Article page — edit <main> to change text. -->
<header class="navbar">
  <div class="logo">
    <img src="images/logo.image.jpg" alt="Logo">
    <span>www.MakeMeInformed.com</span>
  </div>

  <nav class="nav-links">
    <a href="page2.html">Articles &amp; upcoming events</a>
    <a href="page8.html">About us</a>
    <a href="page7.html">Test yourself</a>
    <a href="index.html">Home</a>
  </nav>
</header>

<main>
<section class="content">
  <div class="left-column">
    <h2>
        <a href="page2.html#articles">ARTICLES</a>
    </h2>
    <h1>Information bubbles & confirmation bias</h1>
    <div class="article-body">
    <p class="note">Misinformation, Information Bubbles, and Confirmation Bias
Concerns about misinformation are often closely linked to fears of “information bubbles,” echo chambers, and confirmation bias—especially in online environments. Confirmation bias refers to the human tendency to seek out, prefer, and trust information that aligns with existing beliefs while giving less attention to information that challenges them. Research shows that this tendency is real and widespread, but its effects online are often more complex and less extreme than popular narratives suggest.
Humans naturally gravitate toward familiar and belief-consistent information, and this pattern appears across all forms of media, including print, broadcast, social media, and online news. While digital environments make selective exposure easier—due to vast choice, personalization, and low switching costs—they do not automatically strengthen confirmation bias. Studies comparing online and print media consumption find no major differences in how strongly people prefer politically agreeable content. In other words, people were already selective before the internet; online media mainly make that selectivity more convenient, not fundamentally stronger.
That said, algorithms can amplify existing biases. Platforms such as YouTube, Facebook, and TikTok use personalization systems that recommend content similar to what users have previously engaged with. Over time, this can reinforce confirmation bias and deepen information bubbles, especially when users consistently interact with one-sided or emotionally engaging content. However, this amplification reflects pre-existing preferences rather than creating them from scratch.
Despite common fears of airtight “echo chambers,” research consistently shows that most people still encounter opposing viewpoints, often more online than offline. Exposure alone, however, does not guarantee engagement. People may scroll past, ignore, or actively reject disagreeable content. This means that while cross-cutting information exists in many users’ feeds, confirmation bias often operates at the level of attention and acceptance rather than total isolation.
Filter bubbles can be understood at two different levels. At the technological level, personalization algorithms shape individual information feeds based on signals such as clicks, likes, and viewing time. At the societal level, there are broader concerns that these technologies may harm democracy by increasing polarization or division. Importantly, evidence for strong societal-level effects is limited. Personalization does not automatically translate into large-scale ideological segregation.
Research on selective exposure further shows that while people prefer supportive information, avoidance of challenging information is weaker and inconsistent. Individuals do not completely shut out opposing views, which suggests that the idea of people living in perfectly sealed ideological bubbles is overstated. Moreover, online behavior is a poor indicator of true beliefs. Clicks and likes may reflect curiosity, accidental engagement, boredom, or social motivations rather than genuine ideological commitment. As a result, algorithms may personalize content based on incomplete or misleading signals, creating “filter bubbles” that do not accurately represent a person’s real views.
Social networks also tend to be more diverse than the filter-bubble narrative implies. People interact with a wide range of individuals both online and offline, including family members, coworkers, classmates, and acquaintances with differing opinions. Complete social isolation into like-minded groups is rare.
Finally, politics occupies only a small portion of most people’s media consumption. Entertainment, sports, hobbies, and lifestyle content make up the majority of daily media use. By focusing almost exclusively on political content, the filter-bubble narrative exaggerates how dominant political siloing actually is in everyday life.
Overall, research suggests that confirmation bias and personalization do influence information exposure, but their effects are often overstated. Information bubbles are neither universal nor airtight. While algorithms can reinforce existing tendencies, people’s media environments remain more mixed, diverse, and complex than the popular image of total online isolation suggests.</p>
    </div>
  </div>
</section>
</main>

<footer>
  <p>www.MakeMeInformed.com</p>
</footer>

</div>

</body>
</html>